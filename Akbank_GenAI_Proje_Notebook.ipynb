{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2m1G0ZkXya7",
        "outputId": "537a9cf2-8c64-4d8d-e06a-0512cd22dd2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 351.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "LICENSE  README.md  requirements.txt  tarifler.txt\n"
          ]
        }
      ],
      "source": [
        "# 1. Gerekli kÃ¼tÃ¼phaneleri kuruyoruz\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community\n",
        "\n",
        "# 2. Veri setimizi (tarifler.txt) iÃ§eren GitHub reponuzu klonluyoruz\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "\n",
        "# 3. DosyalarÄ±n gelip gelmediÄŸini kontrol ediyoruz\n",
        "!ls akbank-genai-bootcamp-proje"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Proje Mimarisi iÃ§in LangChain bileÅŸenlerini import et\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings  # Embedding model\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI       # Generation model\n",
        "from langchain.document_loaders import TextLoader                 # Veri yÃ¼kleyici\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Veri parÃ§alayÄ±cÄ±\n",
        "from langchain.vectorstores import FAISS                          # VektÃ¶r veritabanÄ±\n",
        "from langchain.chains import RetrievalQA                          # RAG zinciri\n",
        "\n",
        "# --- API ANAHTARI YÃœKLEME ---\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "    print(\"RAG Mimarisi iÃ§in hazÄ±rÄ±z.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keHX9LTfbLwZ",
        "outputId": "30438ff5-05bb-49d0-aa98-f913621ee97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "RAG Mimarisi iÃ§in hazÄ±rÄ±z.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Veri YÃ¼kleme (Load) ---\n",
        "# KlonladÄ±ÄŸÄ±mÄ±z reponun iÃ§indeki tarifler.txt dosyasÄ±nÄ± yÃ¼klÃ¼yoruz.\n",
        "loader = TextLoader(\"akbank-genai-bootcamp-proje/tarifler.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# --- 2. Veri ParÃ§alama (Split) ---\n",
        "# Tarifleri birbirinden ayÄ±rmak ve RAG iÃ§in optimize etmek amacÄ±yla\n",
        "# metni '---' (tarif ayÄ±racÄ±) ile bÃ¶lÃ¼yoruz.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"---\", \"\\n\\n\", \"\\n\", \" \"], # Tarifleri '---' ile ayÄ±r\n",
        "    chunk_size=1000, # Her bir parÃ§anÄ±n maksimum boyutu\n",
        "    chunk_overlap=200 # ParÃ§alar arasÄ± bindirme, anlamsal bÃ¼tÃ¼nlÃ¼k iÃ§in\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# KaÃ§ adet metin parÃ§asÄ± (chunk) oluÅŸtuÄŸunu gÃ¶relim\n",
        "print(f\"{len(texts)} adet metin parÃ§asÄ± (chunk) oluÅŸturuldu.\")\n",
        "\n",
        "# --- 3. Embedding & VektÃ¶r VeritabanÄ± OluÅŸturma (Embed & Store) ---\n",
        "# Proje dosyasÄ±nda Ã¶nerilen Google embedding modelini kullanÄ±yoruz\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# ParÃ§alanmÄ±ÅŸ metinleri (texts) ve embedding modelini kullanarak\n",
        "# Proje dosyasÄ±nda Ã¶nerilen FAISS vektÃ¶r veritabanÄ±nÄ± oluÅŸturuyoruz.\n",
        "try:\n",
        "    vector_store = FAISS.from_documents(texts, embeddings)\n",
        "    print(\"\\nâœ… VektÃ¶r veritabanÄ± (FAISS) baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "    print(\"ArtÄ±k chatbot'a soru sormaya hazÄ±rÄ±z.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±. Hata: {e}\")\n",
        "    print(\"API AnahtarÄ±nÄ±zÄ±n 'Generative AI API' iÃ§in yetkisi olduÄŸundan emin olun.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8tfjtR-bq2f",
        "outputId": "7452c0b2-3057-426a-c493-89ba8aced3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 adet metin parÃ§asÄ± (chunk) oluÅŸturuldu.\n",
            "\n",
            "âŒ HATA: VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±. Hata: Error embedding content: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0 [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n",
            "  quota_id: \"EmbedContentRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n",
            "  quota_id: \"EmbedContentRequestsPerDayPerUserPerProjectPerModel-FreeTier\"\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n",
            "  quota_id: \"EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier\"\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n",
            "  quota_id: \"EmbedContentRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            "]\n",
            "API AnahtarÄ±nÄ±zÄ±n 'Generative AI API' iÃ§in yetkisi olduÄŸundan emin olun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AÃ§Ä±k kaynak embedding modellerini kullanmak iÃ§in\n",
        "!pip install -q -U sentence-transformers"
      ],
      "metadata": {
        "id": "KJjUCJVld4xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google yerine Hugging Face (aÃ§Ä±k kaynak) embedding modelini import ediyoruz\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# --- 1. Veri YÃ¼kleme (Load) ---\n",
        "# (Bu kÄ±sÄ±m aynÄ±, zaten Ã§alÄ±ÅŸmÄ±ÅŸtÄ±)\n",
        "loader = TextLoader(\"akbank-genai-bootcamp-proje/tarifler.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# --- 2. Veri ParÃ§alama (Split) ---\n",
        "# (Bu kÄ±sÄ±m da aynÄ±, zaten Ã§alÄ±ÅŸmÄ±ÅŸtÄ±)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"---\", \"\\n\\n\", \"\\n\", \" \"],\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# KaÃ§ adet metin parÃ§asÄ± (chunk) oluÅŸtuÄŸunu gÃ¶relim\n",
        "print(f\"{len(texts)} adet metin parÃ§asÄ± (chunk) oluÅŸturuldu.\") # 24 adet gÃ¶rmeliyiz\n",
        "\n",
        "# --- 3. Embedding & VektÃ¶r VeritabanÄ± OluÅŸturma (REVÄ°ZE EDÄ°LDÄ°) ---\n",
        "\n",
        "# Proje dosyasÄ±nda Ã¶nerilen aÃ§Ä±k kaynak model seÃ§eneÄŸini kullanÄ±yoruz\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "print(\"\\nAÃ§Ä±k kaynak embedding modeli (Hugging Face) yÃ¼klendi.\")\n",
        "\n",
        "# ParÃ§alanmÄ±ÅŸ metinleri ve YENÄ° embedding modelini kullanarak\n",
        "# FAISS vektÃ¶r veritabanÄ±nÄ± oluÅŸturuyoruz.\n",
        "try:\n",
        "    vector_store = FAISS.from_documents(texts, embeddings)\n",
        "    print(\"\\nâœ… VektÃ¶r veritabanÄ± (FAISS) baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "    print(\"ArtÄ±k chatbot'a soru sormaya hazÄ±rÄ±z.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627,
          "referenced_widgets": [
            "ba56c201ce7d4021b02ae1c219acff6c",
            "69d20cfd66a340af86077ef1532b99c5",
            "20f2cca7d24240fa878957c2945b03f1",
            "71b9de7763234bb9905f6ba8be0034ea",
            "2e512f4aa8ad470d9479fff82e528edc",
            "36850fc0d17d4f0081da667a42ceb5e0",
            "f37412d01e514120ace7d05f7f86dc23",
            "2950326543d0467ca7ddbc5307f83bc2",
            "9c1827c7664c4cab8c11fa8ba250c5e8",
            "00189a15fb0d4105a4df7ca4b0359b05",
            "125377d941564479ac9182c6d6c04df9",
            "2ec9f55dcd3e4849859cdc662c93ca7a",
            "f9cac0abd5bc46d583ed8c03d8b3bfa4",
            "f0dce73175ea4db083d053b3bce6e839",
            "a4cf06de0065411e89316e2a4481088f",
            "ff66f04b9aa54ee6b660ba4b28d2f268",
            "1a6160325d9b409a83be40b8d660db28",
            "5a18a27c825d4b6cbf37cbf9b07b9307",
            "82a1ec9672b446368367180ea40ca5e7",
            "a5cb0b34018649789b705890edbad763",
            "e1d6b15ee6a04f7693b93fa2787f1703",
            "3c70896f1c6a4ccaae1b274318fb5030",
            "d62d239ac5dc4d01b44eca3dbcda07e1",
            "5bdbb4e2ffe4454688dd3f329a1743b5",
            "cd1b67468bb24246aca4ae640f748b0b",
            "d714bc054da4426a82280dac0679274c",
            "cea47fa534c948cfa6ac7f10cf002c05",
            "2dece97ade6b4369a14f41fa3e1b14d2",
            "9bae390183094ea3ba13d42f815c1d4d",
            "d1db8827ea5b4d249a524c0b70f84d3c",
            "2e36f1af173f4f1daedf7a06310dc642",
            "8c551018c8c14d93bc8b62292f81824b",
            "a9a3281584094be094dceb45c8917fb6",
            "58092eb0271c4076b03de637d386b50b",
            "3a3707ae2f364b0a8342832531505796",
            "a325d2552d734298b9b15037fcf79214",
            "bce8093585394c7396718c85921778c3",
            "6112a7cd69dd497980027bb633c08cde",
            "8baae947d62f4983952b07fd25cb92d2",
            "0cdebac05ff74994ae1922dec8bca614",
            "22e3759ee3254d188328d6d314691727",
            "2c527ef859094eeca7c3e2fa9315ff36",
            "b749c5510c614f408f768b1aea7c8eca",
            "cfc09c014b54467f913f8d2bc12978cf",
            "b1172f1e56c443759d21fb709ed54a44",
            "94a8566a011447c2bcf6ff51dae72e82",
            "4ee6bebf78ea4da39f152e8a1274f1f5",
            "f02a180f700a48e69599ae6b9c432822",
            "2644677166d44b1aaa16bb35f6da7a55",
            "25de8217e0254078b8893f1325cfc119",
            "b2961f1011f84894aa4a6e97f570c8ba",
            "b03ba6134c354358b971fa136a37c17e",
            "86ce86d6f55543b69d47aea67c5a2485",
            "38ff525f91a94ab8b6add8be3fd48857",
            "5698dfee460740eb92bc5ef3b41fd2b2",
            "f1566c5f91d54fdf8a282d4be7dfeb29",
            "94fd21060d6341e48931d2e2c34efc09",
            "7d169ac7b2c640178ac11d4f7246b0ea",
            "55942834a023421e851387b69fc24c01",
            "3b108bcd40714814844de7a8d17daa65",
            "a3fbdc950fd14e9885ad8938d5c77281",
            "5f2c53abaac648748565e30c3f9555fb",
            "f6d798a176384ef9be13c3e0b171ba81",
            "f69f7e5cbd394c129f27d285bbf7f8e0",
            "eaa1d34bb1e746d69f2b0ff671fce713",
            "52e18dd6d7e54095b383e4bd75a7417b",
            "366f43fe8cf14b8bb391306283e82eca",
            "46e1e7f2f4ec4142a430f94267a4853f",
            "418a9329fc034f40a20977abcc216871",
            "729fc7c77d3c40dbb002a92952abb160",
            "b203deb3a0e7437c96c02f9cacf6d859",
            "f4557aa9288d4a0db638c4e66587e335",
            "ef93cbe0c39049e8af3675cfda76dd5d",
            "80f17134f6304f0b98ebecdd69249dab",
            "aaf5051b74cf49d08ade4ca2c36bcea9",
            "d09d6f1ae31e4045859280537a782dbc",
            "84804d850a38409da3280e1fe496a7bf",
            "e7cfd780f9f040fc9424bdca2bf67ba8",
            "c8005bfd9fbc429a8b4ee0c4136ba738",
            "3b419a849da24b1998b4d79bae13ada8",
            "7605c06754094d7c92869a05b79c294a",
            "06d5809c4cab49ad9ec43978387c1060",
            "9f155305a7eb497e80088623c8dc0fc3",
            "b03e1066091842548cbcb7d05ecd3663",
            "1334e5c6406a4d60827e8c526fbc29c1",
            "f2a8b410af114f0b898163ac08b4fb10",
            "8e98f38f4ac441a78672143313b5e7b1",
            "4c80c18c9e2146dcb48cd412eb2358e2",
            "9a8cfbf336074298a4e635bae87bca99",
            "b26ae4eb42684b16aeeb523ab5c8da1e",
            "842e6f63a427423fa67b07f8cee38581",
            "a556a4b7c9ff4918860495e6ea994c77",
            "bd73a393c6d04411a95d2dacfca03549",
            "e08dccc0f31a4f64bffcbd6994128eb3",
            "ac8549638c55447b99dd14c8802dc764",
            "a7a30c873f044cfab11009ad237384b9",
            "b94d1e02d39c4111b7feb4204bd432e8",
            "046f38c4911d49ba80fff88a745a7098",
            "a6811073f881460bae128ad5402aa010",
            "b6b4d921d87c4c4a828115d02f1e1b08",
            "5d2fdeffe4cd4103aef036cf3933531e",
            "c318db472c78429bafa31e99a64bccaa",
            "63f7419dc5904f1eac7ef10f1e3a1457",
            "cff1a20700384329b0b68990ef6239eb",
            "757a0924c77046ff8fbe7bdb9f56679e",
            "b10167d778ac40f3bc46307ee2191404",
            "e359c3b28ac944999ef6531476232bda",
            "566faed1017345eeb78a5a84ea011991",
            "8934ad47fdd040108ebe7d5da9e12729",
            "076757e666c34b45ab01a1fcb73c5975",
            "213e6faa3e474a38b0826162d8200e9d",
            "c70cf90cb0114dbfb495d3e8cf61ba8a",
            "023c6bd0812745f6a65582cebd434d72",
            "cf12c7dd16af4b7ca1652dfd7572d96c",
            "fc53e60c329c46f7a69dc9cdfd7be1c8",
            "18e2360448654e53937bdccf9061a064",
            "5bc2fb778c2747c4acc1174d66dcf726",
            "b7e6aa5dcb0c4550b3523d5f5dd0dddf",
            "49ee2633be2040a7b4ab0e8b2fa4ea2e",
            "ac40eaa8ff6340b385d612dfea0c0bc3",
            "6caacaf8fd7244e9bd22fa825ec3f1a3"
          ]
        },
        "id": "KCMrVNFHeDgM",
        "outputId": "e0636c93-70bf-4b89-a1e5-7bb527810fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 adet metin parÃ§asÄ± (chunk) oluÅŸturuldu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1148925864.py:26: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba56c201ce7d4021b02ae1c219acff6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ec9f55dcd3e4849859cdc662c93ca7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d62d239ac5dc4d01b44eca3dbcda07e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58092eb0271c4076b03de637d386b50b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1172f1e56c443759d21fb709ed54a44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1566c5f91d54fdf8a282d4be7dfeb29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "366f43fe8cf14b8bb391306283e82eca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7cfd780f9f040fc9424bdca2bf67ba8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a8cfbf336074298a4e635bae87bca99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b4d921d87c4c4a828115d02f1e1b08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "213e6faa3e474a38b0826162d8200e9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AÃ§Ä±k kaynak embedding modeli (Hugging Face) yÃ¼klendi.\n",
            "\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) baÅŸarÄ±yla oluÅŸturuldu!\n",
            "ArtÄ±k chatbot'a soru sormaya hazÄ±rÄ±z.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "print(\"API anahtarÄ±nÄ±zÄ±n (generateContent) eriÅŸebildiÄŸi modeller listeleniyor:\")\n",
        "print(\"---------------------------------------------------------------\")\n",
        "model_listesi = []\n",
        "try:\n",
        "    for model in genai.list_models():\n",
        "        # Biz 'generateContent' (sohbet) yapabilen modelleri arÄ±yoruz\n",
        "        if 'generateContent' in model.supported_generation_methods:\n",
        "            model_listesi.append(model.name)\n",
        "            print(f\"âœ… Bulundu: {model.name}\")\n",
        "\n",
        "    if not model_listesi:\n",
        "        print(\"\\nâŒ HATA: 'generateContent' metodunu destekleyen model bulunamadÄ±.\")\n",
        "        print(\"LÃ¼tfen API anahtarÄ±nÄ±zÄ±n Google AI Studio'da doÄŸru ÅŸekilde etkinleÅŸtirildiÄŸinden emin olun.\")\n",
        "    else:\n",
        "        print(f\"\\nğŸ‘‰ Ã–neri: Bir sonraki adÄ±mda bu listedeki modellerden birini kullanÄ±n.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: Modeller listelenemedi. Hata: {e}\")\n",
        "    print(\"API anahtarÄ±nÄ±zda veya baÄŸlantÄ±nÄ±zda bir sorun olabilir.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "Jkaxxjk_fSkU",
        "outputId": "2d7a1b3e-026d-4b65-9905-593c80cc7685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API anahtarÄ±nÄ±zÄ±n (generateContent) eriÅŸebildiÄŸi modeller listeleniyor:\n",
            "---------------------------------------------------------------\n",
            "âœ… Bulundu: models/gemini-2.5-pro-preview-03-25\n",
            "âœ… Bulundu: models/gemini-2.5-flash-preview-05-20\n",
            "âœ… Bulundu: models/gemini-2.5-flash\n",
            "âœ… Bulundu: models/gemini-2.5-flash-lite-preview-06-17\n",
            "âœ… Bulundu: models/gemini-2.5-pro-preview-05-06\n",
            "âœ… Bulundu: models/gemini-2.5-pro-preview-06-05\n",
            "âœ… Bulundu: models/gemini-2.5-pro\n",
            "âœ… Bulundu: models/gemini-2.0-flash-exp\n",
            "âœ… Bulundu: models/gemini-2.0-flash\n",
            "âœ… Bulundu: models/gemini-2.0-flash-001\n",
            "âœ… Bulundu: models/gemini-2.0-flash-exp-image-generation\n",
            "âœ… Bulundu: models/gemini-2.0-flash-lite-001\n",
            "âœ… Bulundu: models/gemini-2.0-flash-lite\n",
            "âœ… Bulundu: models/gemini-2.0-flash-preview-image-generation\n",
            "âœ… Bulundu: models/gemini-2.0-flash-lite-preview-02-05\n",
            "âœ… Bulundu: models/gemini-2.0-flash-lite-preview\n",
            "âœ… Bulundu: models/gemini-2.0-pro-exp\n",
            "âœ… Bulundu: models/gemini-2.0-pro-exp-02-05\n",
            "âœ… Bulundu: models/gemini-exp-1206\n",
            "âœ… Bulundu: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "âœ… Bulundu: models/gemini-2.0-flash-thinking-exp\n",
            "âœ… Bulundu: models/gemini-2.0-flash-thinking-exp-1219\n",
            "âœ… Bulundu: models/gemini-2.5-flash-preview-tts\n",
            "âœ… Bulundu: models/gemini-2.5-pro-preview-tts\n",
            "âœ… Bulundu: models/learnlm-2.0-flash-experimental\n",
            "âœ… Bulundu: models/gemma-3-1b-it\n",
            "âœ… Bulundu: models/gemma-3-4b-it\n",
            "âœ… Bulundu: models/gemma-3-12b-it\n",
            "âœ… Bulundu: models/gemma-3-27b-it\n",
            "âœ… Bulundu: models/gemma-3n-e4b-it\n",
            "âœ… Bulundu: models/gemma-3n-e2b-it\n",
            "âœ… Bulundu: models/gemini-flash-latest\n",
            "âœ… Bulundu: models/gemini-flash-lite-latest\n",
            "âœ… Bulundu: models/gemini-pro-latest\n",
            "âœ… Bulundu: models/gemini-2.5-flash-lite\n",
            "âœ… Bulundu: models/gemini-2.5-flash-image-preview\n",
            "âœ… Bulundu: models/gemini-2.5-flash-image\n",
            "âœ… Bulundu: models/gemini-2.5-flash-preview-09-2025\n",
            "âœ… Bulundu: models/gemini-2.5-flash-lite-preview-09-2025\n",
            "âœ… Bulundu: models/gemini-robotics-er-1.5-preview\n",
            "âœ… Bulundu: models/gemini-2.5-computer-use-preview-10-2025\n",
            "\n",
            "ğŸ‘‰ Ã–neri: Bir sonraki adÄ±mda bu listedeki modellerden birini kullanÄ±n.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Generation Model'i YÃ¼kleme  ---\n",
        "# API anahtarÄ±nÄ±zÄ±n desteklediÄŸi 'gemini-flash-latest' modelini kullanÄ±yoruz.\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "# --- 2. RAG Zincirini (Pipeline) OluÅŸturma ---\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")\n",
        "\n",
        "print(\"âœ… RAG Pipeline (Gemini Flash Latest + FAISS + LangChain) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "# --- 3. RAG Pipeline'Ä±nÄ± Test Etme ---\n",
        "print(\"\\n--- TEST BAÅLIYOR ---\")\n",
        "soru = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru}\")\n",
        "\n",
        "# RAG zincirini Ã§alÄ±ÅŸtÄ±r\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpRLf6i_feZD",
        "outputId": "93be4158-e00c-4b67-f342-69f5868bfb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… RAG Pipeline (Gemini Flash Latest + FAISS + LangChain) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- TEST BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "Bu baÄŸlamda KarnÄ±yarÄ±k tarifi bulunmamaktadÄ±r. Bu yÃ¼zden sorunuzun cevabÄ±nÄ± bilmiyorum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Gerekli Import Ä°ÅŸlemleri ---\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "print(\"Daha gÃ¼Ã§lÃ¼ bir embedding modeli (multilingual) yÃ¼kleniyor...\")\n",
        "print(\"Bu iÅŸlem 1-2 dakika sÃ¼rebilir, model indirilecek...\")\n",
        "\n",
        "# --- 2. GÃœÃ‡LENDÄ°RÄ°LMÄ°Å EMBEDDING MODELÄ° ---\n",
        "# TÃ¼rkÃ§e'yi daha iyi anlayan, popÃ¼ler bir aÃ§Ä±k kaynak model kullanÄ±yoruz.\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "print(f\"\\nâœ… {model_name} modeli baÅŸarÄ±yla yÃ¼klendi.\")\n",
        "\n",
        "# --- 3. VEKTÃ–R VERÄ°TABANINI YENÄ°DEN OLUÅTURMA ---\n",
        "\n",
        "try:\n",
        "    vector_store = FAISS.from_documents(texts, embeddings)\n",
        "    print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) YENÄ° model ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±. Hata: {e}\")\n",
        "\n",
        "# --- 4. RAG PÄ°PELÄ°NE'INI YENÄ°DEN KURMA ---\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")\n",
        "\n",
        "print(\"âœ… RAG Pipeline (Gemini + Yeni Embedding) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "# --- 5. RAG PÄ°PELÄ°NE'INI TEKRAR TEST ETME ---\n",
        "print(\"\\n--- TEST (YENÄ° MODEL Ä°LE) BAÅLIYOR ---\")\n",
        "soru = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541,
          "referenced_widgets": [
            "ee1406c372ba45d79499308f718efe2d",
            "381f9966d808451b9bfbaeec3ed8991b",
            "17c201c3f4f14a08a711701ce729b233",
            "cdbe1d6ad94a4a56b8e068a248bc3388",
            "b44c4794d98d40c3b399c9afbe1f52ac",
            "8cd4d61f99154439abafbf4d8acad39f",
            "d19de6f4b11c404a8d0efea6c27421b0",
            "e67ebe7c850246b4aff4928207c02d0e",
            "18c2644eb026497fbeafeaf547723290",
            "6ca3cd5669fb4bb38a72e2e7018f8427",
            "4a7c19a7c94d42d1a24f237ee0b91433",
            "2bb4d2213be24d479d169214b426088d",
            "cd03fcf6e14a4248a471a726f69bd46b",
            "399b2322575e40cd8551a5785ed4d6a6",
            "50b58716cb13454d8f5a4cf7935cce5c",
            "724138e34170452d8a6c4f380653650f",
            "b5c85b8b9c6f4f0f9da2415f14efb952",
            "d1d7096974404a359b1f9d514a06cb62",
            "daf22c3c5e3a4d52bfca23d66ec4ceab",
            "cdc076aef0904135bbe9b545e4fe0b6b",
            "1fe8e0aee5bc41fc9637a3ce7225ef41",
            "52951b823af6469a8c36c1af73d58cea",
            "e9b9fb2a976a488996dc6f0fcba0a0d0",
            "8bef62fce5b14730a65596836fb60493",
            "511f7e0db53f43d3a56029e25ff22f33",
            "ffe93bdcd2a5426cb443861871222b26",
            "4035d40cba7c49dea0227e1d34a16205",
            "be2cb259100940d1b3fe99ed4c2765f2",
            "8218d5cd043e4abbadad99d954bb7a6e",
            "68a70c6a3fba4259b3aec7fa6aa26a43",
            "fd0b46a179794e2680da7d8e10d5c879",
            "bbbf018def39495d9f0e400a80797f0c",
            "ae3ac011d02b4d359a6f4f1fc2035251",
            "38b1eb5c1b144337809e08c5aab7c484",
            "31569952a7f640728cb92009746a7fc5",
            "6c4865a1796348d79471f04f480e6fef",
            "5eb794857db64dc080b1495351e1b278",
            "f916e0a7ebf64e8ebcb6cbd52852e50c",
            "adfeff856cd948d8be0cefeac7988623",
            "c01bc9deb7f7448f9e77809ed4fcceb0",
            "9f6a06127a66415f90f647aaa89a487d",
            "024e5e1e647c40c3b19fdbf93dbf83c7",
            "b0e17d2a03b74e46ab1fc3696e6a7c42",
            "f68cf8cadb204260add1fba96634585d",
            "ce10cc01ebeb44aebebb616bc66ffaf3",
            "36af07e1f11e4314825dbe33c7302c8e",
            "49f418f051274b33843f2aaeeda5734a",
            "56ad86fb962e44f6aa2d3533a2541249",
            "3a81d4c33cc947a5b4ad8440b324200b",
            "a8ef8ab2d0f54a37baeacb31512e9a54",
            "06b2eb32a90541089d231767e030e021",
            "f29560182d4447e59edbe90d40963e39",
            "d945299c5bf54202b50ed1a541cabafb",
            "10dcbcc256514baabd208f8369bf1681",
            "86855ded0ba645779928950efb8bc249",
            "24207c6775a64354b63aad625cd3aca1",
            "fcc8af5fd5d54164a4502a731a30e401",
            "e820793dadcb4706b447434fbe29c04c",
            "b7f4b217a9424b9ab929e244d31f8951",
            "a9b5ef67e1704bddbcf43bf6cf464255",
            "abe1c17229414035bbd2e7ec8a930b03",
            "9b0cb273925c469f8a6ae7227f38017b",
            "093f453b11fa4761963b65a5de946309",
            "c97e2683d18c423aa71a20a5850ba2dc",
            "559322fb9990400a81bf4ff3c563ccd9",
            "74756cfa530c415496bc239df3a45595",
            "a3ffe564af804561b70f956fa1db83d0",
            "b5647a3da0a64ed491d10abe0df43799",
            "87e1725b08424d3fb470e72f468c30a2",
            "462edbca60fc445dadee03c60e2184f7",
            "f4ec5cef78f34a7699f8ea8ee98b85dc",
            "04c7a553708b4ac89023150465b2558d",
            "6ee483b7eda74084a59a062e52e8637c",
            "32b05c8902d94eccbac5d30812587290",
            "51347c4060084d099890d5fe8e7179da",
            "9167b4720339469fba384d84181d5f20",
            "efc4adc891b14f4f8c7ada7ad27a260a",
            "d8ff020f6aab483ca3b579d52f0b08f9",
            "281830d8931b43fa9d29e1e319cc40f8",
            "fc0241fc1a394802a9782ee00117ffb6",
            "20a9f9a2667441399ea1d060768aed1b",
            "a24d995454c44ca88ae1fa384e078231",
            "1c7637d6cee84324a9a3f9cae0c0ef93",
            "85d1cdef89fa443699dbf665537ee098",
            "b559049ef06e430e8fef194b9fce73a6",
            "445157401dbd415ba2d437d305a4b2e1",
            "f5dade5fa50b48178f0bb30d1f99f901",
            "b91440362dc340518398b46b366938e6",
            "f8cf16530349484f813bae3fbb00db62",
            "b004d44e4f7a4b79bfe200a9e3602de2",
            "77ac7f21a9914bee9e7fe6959692c529",
            "f62b7a463b6145d7ab8ed44924d66480",
            "db1784ebfdb54a7da3ec89d1c0437994",
            "c2e7cc59b28a470aba06e1dcb123f477",
            "102388c2d22d43f0b2c4814735a1c686",
            "17376d2c51b84fb184982784ab980f20",
            "6a0713212a8349549e3bf702a6de253b",
            "77bdfec6aec846beabc619c38836c062",
            "feefcfe10b96491eb32ad9c50158e32c",
            "cec933996c2b423ea2fec12725c41842",
            "4fbcefa08d974d5c988940c1d5c17016",
            "bcc339aa62f44fab8e115970ccc0f709",
            "cfe493a1b917463fa416b8e03ab888de",
            "74f65f321dbb489093e4d0f47ae18631",
            "c97bda3eafb043ab9db917303558a574",
            "063887765a79488884dd70f9dc722ba5",
            "98b68ad9abc54a7d82816ba53ab33049",
            "be09982936c54a0ab0ed13f3225c9000",
            "13a8a2b6f29e4f0699f1ed5d6a866b82",
            "a9f99b9197754ec28d7b9d16536258e3"
          ]
        },
        "id": "IeOA9dUlgK0w",
        "outputId": "a535e3fc-188d-4a4d-86ca-cd89c56d4947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daha gÃ¼Ã§lÃ¼ bir embedding modeli (multilingual) yÃ¼kleniyor...\n",
            "Bu iÅŸlem 1-2 dakika sÃ¼rebilir, model indirilecek...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee1406c372ba45d79499308f718efe2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bb4d2213be24d479d169214b426088d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9b9fb2a976a488996dc6f0fcba0a0d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38b1eb5c1b144337809e08c5aab7c484"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce10cc01ebeb44aebebb616bc66ffaf3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24207c6775a64354b63aad625cd3aca1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3ffe564af804561b70f956fa1db83d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8ff020f6aab483ca3b579d52f0b08f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8cf16530349484f813bae3fbb00db62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cec933996c2b423ea2fec12725c41842"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 modeli baÅŸarÄ±yla yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) YENÄ° model ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "âœ… RAG Pipeline (Gemini + Yeni Embedding) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- TEST (YENÄ° MODEL Ä°LE) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "Elimdeki mevcut metinlerde KarnÄ±yarÄ±k tarifi ve malzemeleri bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Gerekli Import Ä°ÅŸlemleri ---\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document # Belgeleri manuel oluÅŸturmak iÃ§in\n",
        "\n",
        "print(\"RAG Pipeline'Ä± manuel veri parÃ§alama ile yeniden kuruyoruz...\")\n",
        "\n",
        "# --- 2. Veri YÃ¼kleme ve MANUEL ParÃ§alama (EN Ã–NEMLÄ° DÃœZELTME) ---\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    # Tarifleri '---' ayÄ±racÄ±na gÃ¶re bÃ¶lÃ¼yoruz\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "\n",
        "    # LangChain'in anlayacaÄŸÄ± 'Document' formatÄ±na Ã§eviriyoruz\n",
        "    documents = []\n",
        "    for tarif in tarif_listesi:\n",
        "        if tarif.strip(): # BoÅŸluklarÄ± temizle\n",
        "            documents.append(Document(page_content=tarif.strip()))\n",
        "\n",
        "    print(f\"\\nâœ… Veri baÅŸarÄ±yla yÃ¼klendi ve manuel olarak {len(documents)} adet tarife bÃ¶lÃ¼ndÃ¼.\")\n",
        "    print(\"(Her bir belge artÄ±k tam bir tarifi iÃ§eriyor)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: tarifler.txt okunurken veya parÃ§alanÄ±rken hata: {e}\")\n",
        "\n",
        "\n",
        "# --- 3. Embedding Modelini YÃ¼kleme ---\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# --- 4. VEKTÃ–R VERÄ°TABANINI YENÄ°DEN OLUÅTURMA ---\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) doÄŸru parÃ§alama ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "\n",
        "# --- 5. RAG PÄ°PELÄ°NE'INI YENÄ°DEN KURMA ---\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (Gemini + Manuel Chunking) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "# --- 6. RAG PÄ°PELÄ°NE'INI NÄ°HAÄ° TEST ETME ---\n",
        "print(\"\\n--- NÄ°HAÄ° TEST BAÅLIYOR ---\")\n",
        "soru = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZB8RAHtgeHq",
        "outputId": "6728aad0-1d11-4236-8a02-cf3bb9a372b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Pipeline'Ä± manuel veri parÃ§alama ile yeniden kuruyoruz...\n",
            "\n",
            "âœ… Veri baÅŸarÄ±yla yÃ¼klendi ve manuel olarak 10 adet tarife bÃ¶lÃ¼ndÃ¼.\n",
            "(Her bir belge artÄ±k tam bir tarifi iÃ§eriyor)\n",
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) doÄŸru parÃ§alama ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "âœ… RAG Pipeline (Gemini + Manuel Chunking) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "SaÄŸlanan metinler arasÄ±nda KarnÄ±yarÄ±k tarifi bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Gerekli Import Ä°ÅŸlemleri ---\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "import time\n",
        "\n",
        "print(\"RAG Pipeline'Ä± en gÃ¼Ã§lÃ¼ 'open source' model ile yeniden kuruyoruz...\")\n",
        "print(\"LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# --- 2. Veri YÃ¼kleme ve MANUEL ParÃ§alama ---\n",
        "with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    tum_tarifler_metni = f.read()\n",
        "\n",
        "tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "documents = []\n",
        "for tarif in tarif_listesi:\n",
        "    if tarif.strip():\n",
        "        documents.append(Document(page_content=tarif.strip()))\n",
        "\n",
        "print(f\"\\nâœ… Veri yÃ¼klendi ve {len(documents)} adet tarife bÃ¶lÃ¼ndÃ¼.\")\n",
        "\n",
        "# --- 3. EN GÃœÃ‡LÃœ EMBEDDING MODELÄ°NÄ° YÃœKLEME ---\n",
        "# MiniLM yerine, daha bÃ¼yÃ¼k ve daha baÅŸarÄ±lÄ± olan 'mpnet' modelini kullanÄ±yoruz.\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# --- 4. VEKTÃ–R VERÄ°TABANINI YENÄ°DEN OLUÅTURMA ---\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' modeli ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# --- 5. !!! YENÄ° DEBUG ADIMI: RETRIEVAL KONTROLÃœ !!! ---\n",
        "print(\"\\n--- DEBUG: RETRIEVAL KONTROLÃœ BAÅLADI ---\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    # VeritabanÄ±nda 'KarnÄ±yarÄ±k tarifi'ne en Ã§ok benzeyen 1 belgeyi ara\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=1)\n",
        "    if benzer_belgeler:\n",
        "        print(f\"'{soru_test}' sorusuna en Ã§ok benzeyen belge:\")\n",
        "        # Ã‡ok uzun olmasÄ±n diye bulunan belgenin ilk 150 karakterini yazdÄ±rÄ±yoruz\n",
        "        print(benzer_belgeler[0].page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(f\"'{soru_test}' sorusuna benzer belge BULUNAMADI.\")\n",
        "except Exception as e:\n",
        "    print(f\"DEBUG hatasÄ±: {e}\")\n",
        "print(\"--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "\n",
        "# --- 6. RAG PÄ°PELÄ°NE'INI YENÄ°DEN KURMA ---\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (Gemini + 'mpnet' Embedding) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "# --- 7. RAG PÄ°PELÄ°NE'INI NÄ°HAÄ° TEST ETME ---\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (mpnet modeli ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "953puA1ShNSH",
        "outputId": "fa4a058f-aaec-4040-d673-fdc03d510607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Pipeline'Ä± en gÃ¼Ã§lÃ¼ 'open source' model ile yeniden kuruyoruz...\n",
            "LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\n",
            "\n",
            "âœ… Veri yÃ¼klendi ve 10 adet tarife bÃ¶lÃ¼ndÃ¼.\n",
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-mpnet-base-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' modeli ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 6.51 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- DEBUG: RETRIEVAL KONTROLÃœ BAÅLADI ---\n",
            "'KarnÄ±yarÄ±k tarifi' sorusuna en Ã§ok benzeyen belge:\n",
            "BaÅŸlÄ±k: Ä°Ã§li KÃ¶fte\n",
            "Malzemeler:\n",
            "DÄ±ÅŸ HarcÄ± Ä°Ã§in:\n",
            "- 2 su bardaÄŸÄ± ince bulgur (kÃ¶ftelik)\n",
            "- 1 su bardaÄŸÄ± irmik\n",
            "- 1 adet yumurta\n",
            "- 1 yemek kaÅŸÄ±ÄŸÄ± biber salÃ§...\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "âœ… RAG Pipeline (Gemini + 'mpnet' Embedding) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (mpnet modeli ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "Bu bilgiye gÃ¶re KarnÄ±yarÄ±k tarifini ve malzemelerini bilmiyorum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- AdÄ±m 1: Eski Klonu Silme ---\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "print(\"Eski repo kopyasÄ± silindi.\")\n",
        "\n",
        "# --- AdÄ±m 2: Reponun GÃ¼ncel Halini Yeniden Klonlama ---\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"\\nReponun gÃ¼ncel hali klonlandÄ±.\")\n",
        "\n",
        "# --- AdÄ±m 3: 'tarifler.txt' DosyasÄ±nÄ±n Ä°Ã§eriÄŸini Kontrol Etme ---\n",
        "print(\"\\n--- GÃœNCEL DOSYA Ä°Ã‡ERÄ°K KONTROLÃœ ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        icerik = f.read()\n",
        "\n",
        "    if \"KarnÄ±yarÄ±k\" in icerik and \"Menemen\" in icerik:\n",
        "        print(\"âœ… BAÅARILI: 'KarnÄ±yarÄ±k' ve 'Menemen' tarifleri gÃ¼ncel dosyada bulundu!\")\n",
        "        print(\"Åimdi RAG pipeline'Ä±nÄ± tekrar kurabilirsiniz.\")\n",
        "    else:\n",
        "        print(\"âŒ KRÄ°TÄ°K HATA: 'KarnÄ±yarÄ±k' tarifi dosyada hala bulunamÄ±yor.\")\n",
        "        print(\"LÃ¼tfen GitHub reponuza 'tarifler.txt' dosyasÄ±nÄ± (10 tarifin tamamÄ±nÄ±) eklediÄŸinizden emin olun.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"HATA: Dosya okunamadÄ±. {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPD5Yd-uiWqu",
        "outputId": "b12bc31d-bce6-455e-c51e-5370f9aaca54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eski repo kopyasÄ± silindi.\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 3.89 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "\n",
            "Reponun gÃ¼ncel hali klonlandÄ±.\n",
            "\n",
            "--- GÃœNCEL DOSYA Ä°Ã‡ERÄ°K KONTROLÃœ ---\n",
            "âœ… BAÅARILI: 'KarnÄ±yarÄ±k' ve 'Menemen' tarifleri gÃ¼ncel dosyada bulundu!\n",
            "Åimdi RAG pipeline'Ä±nÄ± tekrar kurabilirsiniz.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# === ADIM 1: KURULUM ===\n",
        "print(\"--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\")\n",
        "# Proje dosyasÄ±nÄ±n istediÄŸi tÃ¼m teknolojileri kur\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community sentence-transformers\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler kuruldu.\")\n",
        "\n",
        "# === ADIM 2: API ANAHTARI VE IMPORTLAR ===\n",
        "print(\"\\n--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\")\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "import time\n",
        "\n",
        "try:\n",
        "    # Colab Secrets (ğŸ”‘) bÃ¶lÃ¼mÃ¼nden API anahtarÄ±nÄ± al\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")\n",
        "    # API AnahtarÄ± olmadan devam etme\n",
        "    sys.exit(\"API AnahtarÄ± hatasÄ±. LÃ¼tfen 'Secrets' bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin.\")\n",
        "\n",
        "# === ADIM 3: GÃœNCEL VERÄ°YÄ° Ã‡EKME ===\n",
        "print(\"\\n--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\")\n",
        "# Ã–nce eski, bozuk klonu sil\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "# GÃ¼ncel repoyu klonla\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"âœ… GÃ¼ncel repo klonlandÄ±.\")\n",
        "\n",
        "# === ADIM 4: VERÄ° YÃœKLEME VE MANUEL PARÃ‡ALAMA ===\n",
        "print(\"\\n--- ADIM 4: Veri yÃ¼kleniyor ve manuel parÃ§alanÄ±yor... ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    # Tarifleri '---' ayÄ±racÄ±na gÃ¶re bÃ¶l\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "    documents = []\n",
        "    for tarif in tarif_listesi:\n",
        "        if tarif.strip():\n",
        "            documents.append(Document(page_content=tarif.strip()))\n",
        "\n",
        "    print(f\"âœ… Veri baÅŸarÄ±yla yÃ¼klendi ve {len(documents)} adet tarife bÃ¶lÃ¼ndÃ¼.\")\n",
        "    # KarnÄ±yarÄ±k'Ä±n dosyada olduÄŸunu bir daha kontrol et\n",
        "    if \"KarnÄ±yarÄ±k\" not in tum_tarifler_metni:\n",
        "        print(\"âŒ UYARI: 'KarnÄ±yarÄ±k' metni dosyada bulunamadÄ±. LÃ¼tfen GitHub'Ä± kontrol edin.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: tarifler.txt okunurken veya parÃ§alanÄ±rken hata: {e}\")\n",
        "    sys.exit(\"Veri yÃ¼kleme hatasÄ±.\")\n",
        "\n",
        "# === ADIM 5: EMBEDDING VE VEKTÃ–R DB ===\n",
        "print(\"\\n--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\")\n",
        "print(\"LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Proje dosyasÄ±nda izin verilen \"open source\" model\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# Temiz 'documents' listesi ile VektÃ¶r DB'yi oluÅŸtur\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' modeli ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# === ADIM 6: DEBUG KONTROLÃœ ===\n",
        "print(\"\\n--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ ---\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    # VektÃ¶r DB'de arama yap\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=1)\n",
        "\n",
        "    # DÃ¶nen belgenin iÃ§eriÄŸini kontrol et\n",
        "    if benzer_belgeler and \"KarnÄ±yarÄ±k\" in benzer_belgeler[0].page_content:\n",
        "        print(f\"âœ… DEBUG BAÅARILI: '{soru_test}' sorusuna en Ã§ok benzeyen belge:\")\n",
        "        print(benzer_blog = benzer_belgeler[0].page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(f\"âŒ DEBUG BAÅARISIZ: '{soru_test}' sorusuna benzer belge 'KarnÄ±yarÄ±k' deÄŸil veya bulunamadÄ±.\")\n",
        "        if benzer_belgeler:\n",
        "             print(\"DÃ¶nen belge:\", benzer_belgeler[0].page_content[:150] + \"...\")\n",
        "        else:\n",
        "            print(\"HiÃ§ belge dÃ¶nemedi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ DEBUG hatasÄ±: {e}\")\n",
        "print(\"--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "# === ADIM 7: RAG PIPELINE VE NÄ°HAÄ° TEST ===\n",
        "print(\"--- ADIM 7: RAG Pipeline kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "# Proje dosyasÄ±nda izin verilen \"Generation model\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "# Proje dosyasÄ±nda izin verilen \"RAG pipeline framework\" (LangChain)\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (Gemini + 'mpnet' Embedding) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (mpnet modeli ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V1Rhsfdjpwo",
        "outputId": "3f807a24-2727-4be2-fdf2-40202b940ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\n",
            "âœ… KÃ¼tÃ¼phaneler kuruldu.\n",
            "\n",
            "--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\n",
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "\n",
            "--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 11.68 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "âœ… GÃ¼ncel repo klonlandÄ±.\n",
            "\n",
            "--- ADIM 4: Veri yÃ¼kleniyor ve manuel parÃ§alanÄ±yor... ---\n",
            "âœ… Veri baÅŸarÄ±yla yÃ¼klendi ve 10 adet tarife bÃ¶lÃ¼ndÃ¼.\n",
            "\n",
            "--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\n",
            "LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1347041822.py:68: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-mpnet-base-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' modeli ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 21.51 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ ---\n",
            "âŒ DEBUG BAÅARISIZ: 'KarnÄ±yarÄ±k tarifi' sorusuna benzer belge 'KarnÄ±yarÄ±k' deÄŸil veya bulunamadÄ±.\n",
            "DÃ¶nen belge: BaÅŸlÄ±k: Ä°Ã§li KÃ¶fte\n",
            "Malzemeler:\n",
            "DÄ±ÅŸ HarcÄ± Ä°Ã§in:\n",
            "- 2 su bardaÄŸÄ± ince bulgur (kÃ¶ftelik)\n",
            "- 1 su bardaÄŸÄ± irmik\n",
            "- 1 adet yumurta\n",
            "- 1 yemek kaÅŸÄ±ÄŸÄ± biber salÃ§...\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "--- ADIM 7: RAG Pipeline kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (Gemini + 'mpnet' Embedding) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (mpnet modeli ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "SaÄŸlanan metinlerde KarnÄ±yarÄ±k tarifi bulunmamaktadÄ±r. YalnÄ±zca benzer bir yemek olan Ä°mam BayÄ±ldÄ±'nÄ±n tarifi mevcuttur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "# === ADIM 1: KURULUM ===\n",
        "print(\"--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\")\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community sentence-transformers\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler kuruldu.\")\n",
        "\n",
        "# === ADIM 2: API ANAHTARI VE IMPORTLAR ===\n",
        "print(\"\\n--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\")\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "# YENÄ°: RecursiveCharacterTextSplitter'Ä± tekrar kullanacaÄŸÄ±z, ama daha akÄ±llÄ±ca.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")\n",
        "    sys.exit(\"API AnahtarÄ± hatasÄ±.\")\n",
        "\n",
        "# === ADIM 3: GÃœNCEL VERÄ°YÄ° Ã‡EKME ===\n",
        "print(\"\\n--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\")\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"âœ… GÃ¼ncel repo klonlandÄ±.\")\n",
        "\n",
        "# === ADIM 4: YENÄ° SEMANTÄ°K PARÃ‡ALAMA (STRATEJÄ° DEÄÄ°ÅÄ°KLÄ°ÄÄ°) ===\n",
        "print(\"\\n--- ADIM 4: Veri yÃ¼kleniyor ve SEMANTÄ°K olarak parÃ§alanÄ±yor... ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    # Ã–NCE: Tarifleri '---' ayÄ±racÄ±na gÃ¶re ayÄ±r\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "    print(f\"{len(tarif_listesi)} adet ana tarif bulundu.\")\n",
        "\n",
        "    # SONRA: Her tarifi kendi iÃ§inde semantik olarak bÃ¶lmek iÃ§in bir ayÄ±rÄ±cÄ± tanÄ±mla\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        # Bu ayÄ±rÄ±cÄ±lar tarif yapÄ±mÄ±za Ã¶zel:\n",
        "        separators=[\"BaÅŸlÄ±k: \", \"\\nMalzemeler:\\n\", \"\\nYapÄ±lÄ±ÅŸÄ±:\\n\", \"\\n\\n\", \"\\n\"],\n",
        "        chunk_size=500, # Chunklar daha kÃ¼Ã§Ã¼k ve odaklÄ± olsun\n",
        "        chunk_overlap=50\n",
        "    )\n",
        "\n",
        "    all_chunks = []\n",
        "    # Her bir tarifi (10 adet) alÄ±p, kendi iÃ§inde parÃ§alÄ±yoruz\n",
        "    for tarif_metni in tarif_listesi:\n",
        "        if tarif_metni.strip():\n",
        "            # 'create_documents' metni bÃ¶lÃ¼mlere ayÄ±rÄ±r\n",
        "            chunks = text_splitter.create_documents([tarif_metni.strip()])\n",
        "            all_chunks.extend(chunks)\n",
        "\n",
        "    print(f\"âœ… Veri baÅŸarÄ±yla {len(all_chunks)} adet kÃ¼Ã§Ã¼k semantik parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Veri yÃ¼kleme veya parÃ§alama hatasÄ±: {e}\")\n",
        "    sys.exit(\"Veri yÃ¼kleme hatasÄ±.\")\n",
        "\n",
        "# === ADIM 5: EMBEDDING VE VEKTÃ–R DB ===\n",
        "print(\"\\n--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\")\n",
        "print(\"LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# VektÃ¶r DB'yi kÃ¼Ã§Ã¼k parÃ§alarla (all_chunks) oluÅŸtur\n",
        "vector_store = FAISS.from_documents(all_chunks, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' ve semantik chunking ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# === ADIM 6: DEBUG KONTROLÃœ ===\n",
        "print(\"\\n--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ ---\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    # VektÃ¶r DB'de arama yap\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=1)\n",
        "\n",
        "    if benzer_belgeler and \"KarnÄ±yarÄ±k\" in benzer_belgeler[0].page_content:\n",
        "        print(f\"âœ… DEBUG BAÅARILI: '{soru_test}' sorusuna en Ã§ok benzeyen belge:\")\n",
        "        print(benzer_belgeler[0].page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(f\"âŒ DEBUG BAÅARISIZ: '{soru_test}' sorusuna benzer belge 'KarnÄ±yarÄ±k' deÄŸil veya bulunamadÄ±.\")\n",
        "        if benzer_belgeler:\n",
        "             print(\"DÃ¶nen belge:\", benzer_belgeler[0].page_content[:150] + \"...\")\n",
        "        else:\n",
        "            print(\"HiÃ§ belge dÃ¶nemedi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ DEBUG hatasÄ±: {e}\")\n",
        "print(\"--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "# === ADIM 7: RAG PIPELINE VE NÄ°HAÄ° TEST ===\n",
        "print(\"--- ADIM 7: RAG Pipeline kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (Gemini + 'mpnet' + Semantik Chunking) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (Semantik ParÃ§alama ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChzMSoCDqVtF",
        "outputId": "d80fd672-bbb9-41a7-a8d0-c720c4dd2214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\n",
            "âœ… KÃ¼tÃ¼phaneler kuruldu.\n",
            "\n",
            "--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\n",
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "\n",
            "--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 5.84 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "âœ… GÃ¼ncel repo klonlandÄ±.\n",
            "\n",
            "--- ADIM 4: Veri yÃ¼kleniyor ve SEMANTÄ°K olarak parÃ§alanÄ±yor... ---\n",
            "10 adet ana tarif bulundu.\n",
            "âœ… Veri baÅŸarÄ±yla 45 adet kÃ¼Ã§Ã¼k semantik parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼.\n",
            "\n",
            "--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\n",
            "LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\n",
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-mpnet-base-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' ve semantik chunking ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 17.71 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ ---\n",
            "âœ… DEBUG BAÅARILI: 'KarnÄ±yarÄ±k tarifi' sorusuna en Ã§ok benzeyen belge:\n",
            "BaÅŸlÄ±k: KarnÄ±yarÄ±k...\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "--- ADIM 7: RAG Pipeline kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (Gemini + 'mpnet' + Semantik Chunking) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (Semantik ParÃ§alama ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "SaÄŸlanan metinlerde KarnÄ±yarÄ±k'Ä±n yapÄ±lÄ±ÅŸÄ±na veya malzemelerine dair herhangi bir bilgi bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADIM 6 (REVÄ°ZE EDÄ°LDÄ°): DEBUG KONTROLÃœ (k=5) ---\n",
        "print(\"\\n--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=5) ---\")\n",
        "print(\"KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 5 parÃ§ayÄ± (chunk) arÄ±yoruz:\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    # k=1 yerine k=5 (en iyi 5) arÄ±yoruz\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=5)\n",
        "\n",
        "    if benzer_belgeler:\n",
        "        for i, doc in enumerate(benzer_belgeler):\n",
        "            print(f\"\\n--- DÃ–NEN BELGE {i+1} ('KarnÄ±yarÄ±k' iÃ§ermeli) ---\")\n",
        "            print(doc.page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(\"HiÃ§ belge dÃ¶nemedi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ DEBUG hatasÄ±: {e}\")\n",
        "print(\"\\n--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "\n",
        "# --- ADIM 7 (REVÄ°ZE EDÄ°LDÄ°): RAG PIPELINE (k=5) ---\n",
        "print(\"--- ADIM 7: RAG Pipeline (k=5 ile) kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "# !!! EN Ã–NEMLÄ° DEÄÄ°ÅÄ°KLÄ°K BURADA !!!\n",
        "# Retriever'a \"sadece 1 deÄŸil, 5 belge getir\" (k=5) diyoruz.\n",
        "# Bu sayede hem 'BaÅŸlÄ±k' hem 'Malzemeler' hem de 'YapÄ±lÄ±ÅŸÄ±' parÃ§alarÄ± gelecektir.\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever # DÃ¼zeltilmiÅŸ (k=5) retriever'Ä± kullan\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (k=5 ile) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (k=5 ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnt3vsRDq0N1",
        "outputId": "df2ffc1e-866d-4164-9037-d67172b6ea6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=5) ---\n",
            "KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 5 parÃ§ayÄ± (chunk) arÄ±yoruz:\n",
            "\n",
            "--- DÃ–NEN BELGE 1 ('KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KarnÄ±yarÄ±k...\n",
            "\n",
            "--- DÃ–NEN BELGE 2 ('KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: Ä°Ã§li KÃ¶fte...\n",
            "\n",
            "--- DÃ–NEN BELGE 3 ('KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KÃ¼nefe...\n",
            "\n",
            "--- DÃ–NEN BELGE 4 ('KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: ZeytinyaÄŸlÄ± Yaprak Sarma...\n",
            "\n",
            "--- DÃ–NEN BELGE 5 ('KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: Kuru Fasulye...\n",
            "\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "--- ADIM 7: RAG Pipeline (k=5 ile) kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (k=5 ile) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (k=5 ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "Verilen metin parÃ§alarÄ±nda KarnÄ±yarÄ±k'Ä±n yapÄ±lÄ±ÅŸÄ±na veya malzemelerine dair bilgi bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "# === ADIM 1: KURULUM ===\n",
        "print(\"--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\")\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community sentence-transformers\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler kuruldu.\")\n",
        "\n",
        "# === ADIM 2: API ANAHTARI VE IMPORTLAR ===\n",
        "print(\"\\n--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\")\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")\n",
        "    sys.exit(\"API AnahtarÄ± hatasÄ±.\")\n",
        "\n",
        "# === ADIM 3: GÃœNCEL VERÄ°YÄ° Ã‡EKME ===\n",
        "print(\"\\n--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\")\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"âœ… GÃ¼ncel repo klonlandÄ±.\")\n",
        "\n",
        "# === ADIM 4: YENÄ° KONTEKST ENJEKSÄ°YONU PARÃ‡ALAMASI ===\n",
        "print(\"\\n--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "    print(f\"{len(tarif_listesi)} adet ana tarif bulundu.\")\n",
        "\n",
        "    documents = [] # ParÃ§alarÄ± (chunk) tutacak son liste\n",
        "\n",
        "    for tarif_metni in tarif_listesi:\n",
        "        if not tarif_metni.strip():\n",
        "            continue\n",
        "\n",
        "        # 1. BaÅŸlÄ±ÄŸÄ± ayÄ±r (Ä°lk satÄ±r)\n",
        "        parts = tarif_metni.split(\"\\nMalzemeler:\\n\", 1)\n",
        "        if len(parts) < 2: continue # Bozuk format, atla\n",
        "\n",
        "        baslik_content = parts[0].strip() # \"BaÅŸlÄ±k: KarnÄ±yarÄ±k\"\n",
        "\n",
        "        # 2. Malzemeler ve YapÄ±lÄ±ÅŸÄ±'nÄ± ayÄ±r\n",
        "        parts2 = parts[1].split(\"\\nYapÄ±lÄ±ÅŸÄ±:\\n\", 1)\n",
        "        if len(parts2) < 2: continue # Bozuk format, atla\n",
        "\n",
        "        malzemeler_content = parts2[0].strip() # \"- 6 adet patlÄ±can...\"\n",
        "        yapilis_content = parts2[1].strip()   # \"1. PatlÄ±canlarÄ± soyun...\"\n",
        "\n",
        "        # 3. Konteksi enjekte ederek 3 ayrÄ± 'Document' (chunk) oluÅŸtur\n",
        "\n",
        "        # Chunk 1: Sadece BaÅŸlÄ±k (Aramada bunu bulmasÄ± iÃ§in)\n",
        "        documents.append(Document(\n",
        "            page_content=baslik_content,\n",
        "            metadata={\"source\": baslik_content} # Metadata'ya da baÅŸlÄ±ÄŸÄ± ekle\n",
        "        ))\n",
        "\n",
        "        # Chunk 2: BaÅŸlÄ±k + Malzemeler (ArtÄ±k 'KarnÄ±yarÄ±k' bilgisi iÃ§eriyor)\n",
        "        documents.append(Document(\n",
        "            page_content=f\"{baslik_content}\\nMalzemeler:\\n{malzemeler_content}\",\n",
        "            metadata={\"source\": baslik_content}\n",
        "        ))\n",
        "\n",
        "        # Chunk 3: BaÅŸlÄ±k + YapÄ±lÄ±ÅŸÄ± (ArtÄ±k 'KarnÄ±yarÄ±k' bilgisi iÃ§eriyor)\n",
        "        documents.append(Document(\n",
        "            page_content=f\"{baslik_content}\\nYapÄ±lÄ±ÅŸÄ±:\\n{yapilis_content}\",\n",
        "            metadata={\"source\": baslik_content}\n",
        "        ))\n",
        "\n",
        "    print(f\"âœ… Veri baÅŸarÄ±yla {len(documents)} adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼. (10 tarif x 3 parÃ§a = 30)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Veri yÃ¼kleme veya parÃ§alama hatasÄ±: {e}\")\n",
        "    sys.exit(\"Veri yÃ¼kleme hatasÄ±.\")\n",
        "\n",
        "# === ADIM 5: EMBEDDING VE VEKTÃ–R DB ===\n",
        "print(\"\\n--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\")\n",
        "print(\"LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# VektÃ¶r DB'yi KONTEKSTLÄ° parÃ§alarla (documents) oluÅŸtur\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# === ADIM 6: DEBUG KONTROLÃœ (k=3) ===\n",
        "print(\"\\n--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=3) ---\")\n",
        "print(\"KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 3 parÃ§ayÄ± (chunk) arÄ±yoruz:\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    # k=3 arÄ±yoruz (BaÅŸlÄ±k, Malzemeler, YapÄ±lÄ±ÅŸ)\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=3)\n",
        "\n",
        "    if benzer_belgeler:\n",
        "        for i, doc in enumerate(benzer_belgeler):\n",
        "            print(f\"\\n--- DÃ–NEN BELGE {i+1} (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\")\n",
        "            print(doc.page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(\"HiÃ§ belge dÃ¶nemedi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ DEBUG hatasÄ±: {e}\")\n",
        "print(\"\\n--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "# === ADIM 7: RAG PIPELINE VE NÄ°HAÄ° TEST (k=3) ===\n",
        "print(\"--- ADIM 7: RAG Pipeline (k=3 ile) kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "# Retriever'a \"en iyi 3 belgeyi getir\" diyoruz (k=3)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever # DÃ¼zeltilmiÅŸ (k=3) retriever'Ä± kullan\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (k=3 ile) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (Konteks Enjeksiyonu ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25wTL9Ubrg94",
        "outputId": "57274271-2efb-4597-b345-ef707881a087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\n",
            "âœ… KÃ¼tÃ¼phaneler kuruldu.\n",
            "\n",
            "--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\n",
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "\n",
            "--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 11.68 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "âœ… GÃ¼ncel repo klonlandÄ±.\n",
            "\n",
            "--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\n",
            "10 adet ana tarif bulundu.\n",
            "âœ… Veri baÅŸarÄ±yla 30 adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼. (10 tarif x 3 parÃ§a = 30)\n",
            "\n",
            "--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\n",
            "LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\n",
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-mpnet-base-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 14.96 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=3) ---\n",
            "KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 3 parÃ§ayÄ± (chunk) arÄ±yoruz:\n",
            "\n",
            "--- DÃ–NEN BELGE 1 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KarnÄ±yarÄ±k...\n",
            "\n",
            "--- DÃ–NEN BELGE 2 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: Ä°Ã§li KÃ¶fte...\n",
            "\n",
            "--- DÃ–NEN BELGE 3 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KÃ¼nefe...\n",
            "\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "--- ADIM 7: RAG Pipeline (k=3 ile) kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (k=3 ile) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (Konteks Enjeksiyonu ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "SaÄŸlanan baÄŸlamda KarnÄ±yarÄ±k'Ä±n nasÄ±l yapÄ±lacaÄŸÄ± veya malzemeleri hakkÄ±nda bilgi bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "# === ADIM 1: KURULUM ===\n",
        "print(\"--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\")\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community sentence-transformers\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler kuruldu.\")\n",
        "\n",
        "# === ADIM 2: API ANAHTARI VE IMPORTLAR ===\n",
        "print(\"\\n--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\")\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")\n",
        "    sys.exit(\"API AnahtarÄ± hatasÄ±.\")\n",
        "\n",
        "# === ADIM 3: GÃœNCEL VERÄ°YÄ° Ã‡EKME ===\n",
        "print(\"\\n--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\")\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"âœ… GÃ¼ncel repo klonlandÄ±.\")\n",
        "\n",
        "# === ADIM 4: YENÄ° KONTEKST ENJEKSÄ°YONU PARÃ‡ALAMASI ===\n",
        "print(\"\\n--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "    print(f\"{len(tarif_listesi)} adet ana tarif bulundu.\")\n",
        "\n",
        "    documents = [] # ParÃ§alarÄ± (chunk) tutacak son liste\n",
        "\n",
        "    for tarif_metni in tarif_listesi:\n",
        "        if not tarif_metni.strip():\n",
        "            continue\n",
        "\n",
        "        # 1. BaÅŸlÄ±ÄŸÄ± ayÄ±r (Ä°lk satÄ±r)\n",
        "        parts = tarif_metni.split(\"\\nMalzemeler:\\n\", 1)\n",
        "        if len(parts) < 2: continue # Bozuk format, atla\n",
        "\n",
        "        baslik_content = parts[0].strip() # \"BaÅŸlÄ±k: KarnÄ±yarÄ±k\"\n",
        "\n",
        "        # 2. Malzemeler ve YapÄ±lÄ±ÅŸÄ±'nÄ± ayÄ±r\n",
        "        parts2 = parts[1].split(\"\\nYapÄ±lÄ±ÅŸÄ±:\\n\", 1)\n",
        "        if len(parts2) < 2: continue # Bozuk format, atla\n",
        "\n",
        "        malzemeler_content = parts2[0].strip() # \"- 6 adet patlÄ±can...\"\n",
        "        yapilis_content = parts2[1].strip()   # \"1. PatlÄ±canlarÄ± soyun...\"\n",
        "\n",
        "        # 3. Konteksi enjekte ederek 3 ayrÄ± 'Document' (chunk) oluÅŸtur\n",
        "\n",
        "        # Chunk 1: Sadece BaÅŸlÄ±k (Aramada bunu bulmasÄ± iÃ§in)\n",
        "        documents.append(Document(\n",
        "            page_content=baslik_content,\n",
        "            metadata={\"source\": baslik_content} # Metadata'ya da baÅŸlÄ±ÄŸÄ± ekle\n",
        "        ))\n",
        "\n",
        "        # Chunk 2: BaÅŸlÄ±k + Malzemeler (ArtÄ±k 'KarnÄ±yarÄ±k' bilgisi iÃ§eriyor)\n",
        "        documents.append(Document(\n",
        "            page_content=f\"{baslik_content}\\nMalzemeler:\\n{malzemeler_content}\",\n",
        "            metadata={\"source\": baslik_content}\n",
        "        ))\n",
        "\n",
        "        # Chunk 3: BaÅŸlÄ±k + YapÄ±lÄ±ÅŸÄ± (ArtÄ±k 'KarnÄ±yarÄ±k' bilgisi iÃ§eriyor)\n",
        "        documents.append(Document(\n",
        "            page_content=f\"{baslik_content}\\nYapÄ±lÄ±ÅŸÄ±:\\n{yapilis_content}\",\n",
        "            metadata={\"source\": baslik_content}\n",
        "        ))\n",
        "\n",
        "    print(f\"âœ… Veri baÅŸarÄ±yla {len(documents)} adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼. (10 tarif x 3 parÃ§a = 30)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Veri yÃ¼kleme veya parÃ§alama hatasÄ±: {e}\")\n",
        "    sys.exit(\"Veri yÃ¼kleme hatasÄ±.\")\n",
        "\n",
        "# === ADIM 5: EMBEDDING VE VEKTÃ–R DB ===\n",
        "print(\"\\n--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\")\n",
        "print(\"LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# VektÃ¶r DB'yi KONTEKSTLÄ° parÃ§alarla (documents) oluÅŸtur\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# === ADIM 6: DEBUG KONTROLÃœ (k=3) ===\n",
        "print(\"\\n--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=3) ---\")\n",
        "print(\"KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 3 parÃ§ayÄ± (chunk) arÄ±yoruz:\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    # k=3 arÄ±yoruz (BaÅŸlÄ±k, Malzemeler, YapÄ±lÄ±ÅŸ)\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=3)\n",
        "\n",
        "    if benzer_belgeler:\n",
        "        for i, doc in enumerate(benzer_belgeler):\n",
        "            print(f\"\\n--- DÃ–NEN BELGE {i+1} (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\")\n",
        "            print(doc.page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(\"HiÃ§ belge dÃ¶nemedi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ DEBUG hatasÄ±: {e}\")\n",
        "print(\"\\n--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "# === ADIM 7: RAG PIPELINE VE NÄ°HAÄ° TEST (k=3) ===\n",
        "print(\"--- ADIM 7: RAG Pipeline (k=3 ile) kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "\n",
        "# Retriever'a \"en iyi 3 belgeyi getir\" diyoruz (k=3)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever # DÃ¼zeltilmiÅŸ (k=3) retriever'Ä± kullan\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (k=3 ile) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (Konteks Enjeksiyonu ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDdtxquSslRB",
        "outputId": "45145d9a-feba-4db7-e20e-91e85d15419c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\n",
            "âœ… KÃ¼tÃ¼phaneler kuruldu.\n",
            "\n",
            "--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\n",
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "\n",
            "--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 11.68 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "âœ… GÃ¼ncel repo klonlandÄ±.\n",
            "\n",
            "--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\n",
            "10 adet ana tarif bulundu.\n",
            "âœ… Veri baÅŸarÄ±yla 30 adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼. (10 tarif x 3 parÃ§a = 30)\n",
            "\n",
            "--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\n",
            "LÃ¼tfen bekleyin, 'mpnet' modeli (yaklaÅŸÄ±k 1.1 GB) indirilecek...\n",
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-mpnet-base-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) 'mpnet' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 14.17 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=3) ---\n",
            "KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 3 parÃ§ayÄ± (chunk) arÄ±yoruz:\n",
            "\n",
            "--- DÃ–NEN BELGE 1 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KarnÄ±yarÄ±k...\n",
            "\n",
            "--- DÃ–NEN BELGE 2 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: Ä°Ã§li KÃ¶fte...\n",
            "\n",
            "--- DÃ–NEN BELGE 3 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KÃ¼nefe...\n",
            "\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "--- ADIM 7: RAG Pipeline (k=3 ile) kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (k=3 ile) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (Konteks Enjeksiyonu ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "Eldeki baÄŸlamda KarnÄ±yarÄ±k'Ä±n nasÄ±l yapÄ±lacaÄŸÄ±na veya malzemelerine dair herhangi bir bilgi bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "# === ADIM 1: KURULUM ===\n",
        "print(\"--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\")\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community sentence-transformers\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler kuruldu.\")\n",
        "\n",
        "# === ADIM 2: API ANAHTARI VE IMPORTLAR ===\n",
        "print(\"\\n--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\")\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")\n",
        "    sys.exit(\"API AnahtarÄ± hatasÄ±.\")\n",
        "\n",
        "# === ADIM 3: GÃœNCEL VERÄ°YÄ° Ã‡EKME ===\n",
        "print(\"\\n--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\")\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"âœ… GÃ¼ncel repo klonlandÄ±.\")\n",
        "\n",
        "# === ADIM 4: YENÄ° KONTEKST ENJEKSÄ°YONU PARÃ‡ALAMASI ===\n",
        "print(\"\\n--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "    print(f\"{len(tarif_listesi)} adet ana tarif bulundu.\")\n",
        "\n",
        "    documents = [] # ParÃ§alarÄ± (chunk) tutacak son liste\n",
        "\n",
        "    for tarif_metni in tarif_listesi:\n",
        "        if not tarif_metni.strip(): continue\n",
        "        parts = tarif_metni.split(\"\\nMalzemeler:\\n\", 1)\n",
        "        if len(parts) < 2: continue\n",
        "        baslik_content = parts[0].strip()\n",
        "        parts2 = parts[1].split(\"\\nYapÄ±lÄ±ÅŸÄ±:\\n\", 1)\n",
        "        if len(parts2) < 2: continue\n",
        "        malzemeler_content = parts2[0].strip()\n",
        "        yapilis_content = parts2[1].strip()\n",
        "\n",
        "        # Stratejimiz (3 parÃ§a oluÅŸturma) aynÄ±\n",
        "        documents.append(Document(page_content=baslik_content, metadata={\"source\": baslik_content}))\n",
        "        documents.append(Document(page_content=f\"{baslik_content}\\nMalzemeler:\\n{malzemeler_content}\", metadata={\"source\": baslik_content}))\n",
        "        documents.append(Document(page_content=f\"{baslik_content}\\nYapÄ±lÄ±ÅŸÄ±:\\n{yapilis_content}\", metadata={\"source\": baslik_content}))\n",
        "\n",
        "    print(f\"âœ… Veri baÅŸarÄ±yla {len(documents)} adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼. (10 tarif x 3 parÃ§a = 30)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Veri yÃ¼kleme veya parÃ§alama hatasÄ±: {e}\")\n",
        "    sys.exit(\"Veri yÃ¼kleme hatasÄ±.\")\n",
        "\n",
        "# === ADIM 5: EMBEDDING VE VEKTÃ–R DB (MODEL DEÄÄ°ÅÄ°KLÄ°ÄÄ°) ===\n",
        "print(\"\\n--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\")\n",
        "print(\"LÃ¼tfen bekleyin, 'MiniLM' modeli (yaklaÅŸÄ±k 450 MB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# 'mpnet' (baÅŸarÄ±sÄ±z) yerine 'MiniLM' (daha kÃ¼Ã§Ã¼k) modelini kullanÄ±yoruz\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (FAISS) 'MiniLM' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# === ADIM 6: DEBUG KONTROLÃœ (k=3) ===\n",
        "print(\"\\n--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=3) ---\")\n",
        "print(\"KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 3 parÃ§ayÄ± (chunk) arÄ±yoruz:\")\n",
        "soru_test = \"KarnÄ±yarÄ±k tarifi\"\n",
        "try:\n",
        "    benzer_belgeler = vector_store.similarity_search(soru_test, k=3)\n",
        "\n",
        "    if benzer_belgeler:\n",
        "        for i, doc in enumerate(benzer_belgeler):\n",
        "            print(f\"\\n--- DÃ–NEN BELGE {i+1} (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\")\n",
        "            print(doc.page_content[:150] + \"...\")\n",
        "    else:\n",
        "        print(\"HiÃ§ belge dÃ¶nemedi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ DEBUG hatasÄ±: {e}\")\n",
        "print(\"\\n--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\\n\")\n",
        "\n",
        "# === ADIM 7: RAG PIPELINE VE NÄ°HAÄ° TEST (k=3) ===\n",
        "print(\"--- ADIM 7: RAG Pipeline (k=3 ile) kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\",\n",
        "                             temperature=0.7,\n",
        "                             top_p=0.85)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (k=3 ile) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (Konteks Enjeksiyonu + MiniLM) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtac3-xNtmfw",
        "outputId": "d838b01d-6004-4b06-fcb0-5c9f38a452c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\n",
            "âœ… KÃ¼tÃ¼phaneler kuruldu.\n",
            "\n",
            "--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\n",
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "\n",
            "--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 323.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "âœ… GÃ¼ncel repo klonlandÄ±.\n",
            "\n",
            "--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\n",
            "10 adet ana tarif bulundu.\n",
            "âœ… Veri baÅŸarÄ±yla 30 adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼. (10 tarif x 3 parÃ§a = 30)\n",
            "\n",
            "--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB oluÅŸturuluyor... ---\n",
            "LÃ¼tfen bekleyin, 'MiniLM' modeli (yaklaÅŸÄ±k 450 MB) indirilecek...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2425729563.py:73: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (FAISS) 'MiniLM' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 17.72 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- ADIM 6: DEBUG - RETRIEVAL KONTROLÃœ (k=3) ---\n",
            "KarnÄ±yarÄ±k'a benzeyen EN Ä°YÄ° 3 parÃ§ayÄ± (chunk) arÄ±yoruz:\n",
            "\n",
            "--- DÃ–NEN BELGE 1 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: KarnÄ±yarÄ±k...\n",
            "\n",
            "--- DÃ–NEN BELGE 2 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: Menemen...\n",
            "\n",
            "--- DÃ–NEN BELGE 3 (MUTLAKA 'KarnÄ±yarÄ±k' iÃ§ermeli) ---\n",
            "BaÅŸlÄ±k: HÃ¼nkar BeÄŸendi...\n",
            "\n",
            "--- DEBUG KONTROLÃœ BÄ°TTÄ° ---\n",
            "\n",
            "--- ADIM 7: RAG Pipeline (k=3 ile) kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (k=3 ile) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (Konteks Enjeksiyonu + MiniLM) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "SaÄŸlanan metinlerde KarnÄ±yarÄ±k yemeÄŸinin yapÄ±lÄ±ÅŸÄ± veya malzemeleri hakkÄ±nda bilgi bulunmamaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "# === ADIM 1: KURULUM ===\n",
        "print(\"--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\")\n",
        "# Self-Querying iÃ§in 'langchain-chroma' ve 'lark' ekliyoruz\n",
        "!pip install -q -U google-generativeai langchain-google-genai langchain faiss-cpu langchain_community sentence-transformers langchain-chroma lark\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler kuruldu.\")\n",
        "\n",
        "# === ADIM 2: API ANAHTARI VE IMPORTLAR ===\n",
        "print(\"\\n--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\")\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Gerekli LangChain importlarÄ±\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "# YENÄ°: VektÃ¶r veritabanÄ± olarak Chroma\n",
        "from langchain_chroma import Chroma\n",
        "# YENÄ°: SelfQueryRetriever\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: API AnahtarÄ± yÃ¼klenemedi. 'Secrets' (ğŸ”‘) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin. Hata: {e}\")\n",
        "    sys.exit(\"API AnahtarÄ± hatasÄ±.\")\n",
        "\n",
        "# === ADIM 3: GÃœNCEL VERÄ°YÄ° Ã‡EKME ===\n",
        "print(\"\\n--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\")\n",
        "!rm -rf akbank-genai-bootcamp-proje\n",
        "!git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje\n",
        "print(\"âœ… GÃ¼ncel repo klonlandÄ±.\")\n",
        "\n",
        "# === ADIM 4: KONTEKST ENJEKSÄ°YONU PARÃ‡ALAMASI ===\n",
        "print(\"\\n--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\")\n",
        "try:\n",
        "    with open(\"akbank-genai-bootcamp-proje/tarifler.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        tum_tarifler_metni = f.read()\n",
        "\n",
        "    tarif_listesi = tum_tarifler_metni.split(\"\\n---\\n\")\n",
        "    print(f\"{len(tarif_listesi)} adet ana tarif bulundu.\")\n",
        "\n",
        "    documents = [] # ParÃ§alarÄ± (chunk) tutacak son liste\n",
        "\n",
        "    for tarif_metni in tarif_listesi:\n",
        "        if not tarif_metni.strip(): continue\n",
        "        parts = tarif_metni.split(\"\\nMalzemeler:\\n\", 1)\n",
        "        if len(parts) < 2: continue\n",
        "        baslik_content = parts[0].strip() # \"BaÅŸlÄ±k: KarnÄ±yarÄ±k\"\n",
        "        parts2 = parts[1].split(\"\\nYapÄ±lÄ±ÅŸÄ±:\\n\", 1)\n",
        "        if len(parts2) < 2: continue\n",
        "        malzemeler_content = parts2[0].strip()\n",
        "        yapilis_content = parts2[1].strip()\n",
        "\n",
        "        # Self-Querying iÃ§in metadata'yÄ± DÃœZGÃœN tanÄ±mlÄ±yoruz\n",
        "        # 'source' alanÄ± \"BaÅŸlÄ±k: KarnÄ±yarÄ±k\" metnini iÃ§erecek\n",
        "        doc_metadata = {\"source\": baslik_content}\n",
        "\n",
        "        # Stratejimiz (3 parÃ§a oluÅŸturma) aynÄ±\n",
        "        documents.append(Document(page_content=baslik_content, metadata=doc_metadata))\n",
        "        documents.append(Document(page_content=f\"{baslik_content}\\nMalzemeler:\\n{malzemeler_content}\", metadata=doc_metadata))\n",
        "        documents.append(Document(page_content=f\"{baslik_content}\\nYapÄ±lÄ±ÅŸÄ±:\\n{yapilis_content}\", metadata=doc_metadata))\n",
        "\n",
        "    print(f\"âœ… Veri baÅŸarÄ±yla {len(documents)} adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Veri yÃ¼kleme veya parÃ§alama hatasÄ±: {e}\")\n",
        "    sys.exit(\"Veri yÃ¼kleme hatasÄ±.\")\n",
        "\n",
        "# === ADIM 5: EMBEDDING VE VEKTÃ–R DB (Chroma) ===\n",
        "print(\"\\n--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB (Chroma) oluÅŸturuluyor... ---\")\n",
        "print(\"LÃ¼tfen bekleyin, 'MiniLM' modeli (yaklaÅŸÄ±k 450 MB) indirilecek...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# 'mpnet' (kafa karÄ±ÅŸtÄ±ran) yerine 'MiniLM' (hÄ±zlÄ± ve yeterli) modelini kullanÄ±yoruz\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "print(f\"âœ… Embedding modeli ({model_name}) yÃ¼klendi.\")\n",
        "\n",
        "# FAISS yerine Chroma veritabanÄ±nÄ±  kullanÄ±yoruz\n",
        "vector_store = Chroma.from_documents(documents, embeddings)\n",
        "print(\"âœ… VektÃ¶r veritabanÄ± (Chroma) 'MiniLM' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "end_time = time.time()\n",
        "print(f\"(Bu iÅŸlem {end_time - start_time:.2f} saniye sÃ¼rdÃ¼)\")\n",
        "\n",
        "# === ADIM 6: SELF-QUERYING RETRIEVER KURULUMU ===\n",
        "print(\"\\n--- ADIM 6: Self-Querying Retriever kuruluyor... ---\")\n",
        "\n",
        "# LLM (Gemini)  modelini tanÄ±mla\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\", temperature=0)\n",
        "\n",
        "# Retriever'a metadata'mÄ±zÄ±n ne anlama geldiÄŸini Ã¶ÄŸretiyoruz\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"source\",\n",
        "        description=\"Tarifin baÅŸlÄ±ÄŸÄ±, Ã¶rneÄŸin 'BaÅŸlÄ±k: KarnÄ±yarÄ±k' veya 'BaÅŸlÄ±k: Menemen'\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "]\n",
        "document_content_description = \"TÃ¼rk mutfaÄŸÄ± yemek tarifleri\"\n",
        "\n",
        "# Retriever'Ä± oluÅŸtur\n",
        "# Bu, LLM'i (Gemini) ve VektÃ¶r DB'yi (Chroma) birbirine baÄŸlar\n",
        "try:\n",
        "    retriever = SelfQueryRetriever.from_llm(\n",
        "        llm,\n",
        "        vector_store,\n",
        "        document_content_description,\n",
        "        metadata_field_info,\n",
        "        verbose=True # Ã–NEMLÄ°: Gemini'nin filtreyi nasÄ±l oluÅŸturduÄŸunu gÃ¶rmek iÃ§in\n",
        "    )\n",
        "    print(\"âœ… Self-Querying Retriever baÅŸarÄ±yla kuruldu.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Self-Querying Retriever kurulamadÄ±: {e}\")\n",
        "    sys.exit(\"Retriever hatasÄ±.\")\n",
        "\n",
        "# === ADIM 7: RAG PIPELINE VE NÄ°HAÄ° TEST ===\n",
        "print(\"\\n--- ADIM 7: RAG Pipeline kuruluyor ve test ediliyor... ---\")\n",
        "\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm, # Cevap Ã¼retecek model (Gemini)\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever # AkÄ±llÄ± filtreleme yapan retriever\n",
        ")\n",
        "print(\"âœ… RAG Pipeline (Self-Querying ile) baÅŸarÄ±yla kuruldu.\")\n",
        "\n",
        "print(\"\\n--- NÄ°HAÄ° TEST (Self-Querying ile) BAÅLIYOR ---\")\n",
        "soru_final = \"KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\"\n",
        "print(f\"Soru: {soru_final}\")\n",
        "\n",
        "try:\n",
        "    cevap = rag_pipeline.invoke(soru_final)\n",
        "    # Gemini'nin oluÅŸturduÄŸu filtreyi ve bulunan belgeleri gÃ¶receÄŸiz (verbose=True sayesinde)\n",
        "    print(\"\\nCevap:\")\n",
        "    print(cevap['result'])\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model sorgulanamadÄ±. Hata: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR2GNtd6t_H0",
        "outputId": "d25e1cbe-15cb-4de5-fca6-f1437271c91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: KÃ¼tÃ¼phaneler kuruluyor... ---\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.7/20.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… KÃ¼tÃ¼phaneler kuruldu.\n",
            "\n",
            "--- ADIM 2: KÃ¼tÃ¼phaneler ve API AnahtarÄ± yÃ¼kleniyor... ---\n",
            "âœ… API AnahtarÄ± ve KÃ¼tÃ¼phaneler BaÅŸarÄ±yla YÃ¼klendi!\n",
            "\n",
            "--- ADIM 3: GitHub'dan gÃ¼ncel veri seti Ã§ekiliyor... ---\n",
            "Cloning into 'akbank-genai-bootcamp-proje'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 11.68 KiB | 362.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "âœ… GÃ¼ncel repo klonlandÄ±.\n",
            "\n",
            "--- ADIM 4: Veri yÃ¼kleniyor ve KONTEKST ENJEKSÄ°YONU ile parÃ§alanÄ±yor... ---\n",
            "10 adet ana tarif bulundu.\n",
            "âœ… Veri baÅŸarÄ±yla 30 adet KONTEKSTLÄ° parÃ§aya (chunk) bÃ¶lÃ¼ndÃ¼.\n",
            "\n",
            "--- ADIM 5: Embedding modeli yÃ¼kleniyor ve VektÃ¶r DB (Chroma) oluÅŸturuluyor... ---\n",
            "LÃ¼tfen bekleyin, 'MiniLM' modeli (yaklaÅŸÄ±k 450 MB) indirilecek...\n",
            "âœ… Embedding modeli (sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) yÃ¼klendi.\n",
            "âœ… VektÃ¶r veritabanÄ± (Chroma) 'MiniLM' ve 'Konteks Enjeksiyonu' ile baÅŸarÄ±yla oluÅŸturuldu!\n",
            "(Bu iÅŸlem 12.39 saniye sÃ¼rdÃ¼)\n",
            "\n",
            "--- ADIM 6: Self-Querying Retriever kuruluyor... ---\n",
            "âœ… Self-Querying Retriever baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- ADIM 7: RAG Pipeline kuruluyor ve test ediliyor... ---\n",
            "âœ… RAG Pipeline (Self-Querying ile) baÅŸarÄ±yla kuruldu.\n",
            "\n",
            "--- NÄ°HAÄ° TEST (Self-Querying ile) BAÅLIYOR ---\n",
            "Soru: KarnÄ±yarÄ±k nasÄ±l yapÄ±lÄ±r? Malzemeleri nelerdir?\n",
            "\n",
            "Cevap:\n",
            "**Malzemeler:**\n",
            "\n",
            "*   6 adet orta boy patlÄ±can\n",
            "*   300 gram kÄ±yma (orta yaÄŸlÄ±)\n",
            "*   2 adet soÄŸan\n",
            "*   2 adet yeÅŸil biber\n",
            "*   2 diÅŸ sarÄ±msak\n",
            "*   2 adet domates (veya 1 yemek kaÅŸÄ±ÄŸÄ± domates salÃ§asÄ±)\n",
            "*   1 yemek kaÅŸÄ±ÄŸÄ± biber salÃ§asÄ±\n",
            "*   Maydanoz\n",
            "*   Tuz, karabiber\n",
            "*   KÄ±zartmak iÃ§in sÄ±vÄ± yaÄŸ\n",
            "\n",
            "**Sosu iÃ§in:**\n",
            "\n",
            "*   1 yemek kaÅŸÄ±ÄŸÄ± domates salÃ§asÄ±\n",
            "*   2 su baradÄŸÄ± sÄ±cak su\n",
            "\n",
            "***\n",
            "\n",
            "**YapÄ±lÄ±ÅŸÄ±:**\n",
            "\n",
            "1.  PatlÄ±canlarÄ± alacalÄ± soyun ve tuzlu suda 30 dakika bekleterek acÄ±sÄ±nÄ± alÄ±n. KurulayÄ±n.\n",
            "2.  PatlÄ±canlarÄ± kÄ±zgÄ±n yaÄŸda her tarafÄ± yumuÅŸayana kadar kÄ±zartÄ±n ve fazla yaÄŸÄ±nÄ± almasÄ± iÃ§in kaÄŸÄ±t havlu Ã¼zerine alÄ±n.\n",
            "3.  Ä°Ã§ harcÄ± iÃ§in; soÄŸanlarÄ± yemeklik doÄŸrayÄ±n, biberleri ve sarÄ±msaklarÄ± ince kÄ±yÄ±n.\n",
            "4.  Bir tavada kÄ±ymayÄ± suyunu Ã§ekene kadar kavurun. ArdÄ±ndan soÄŸan, biber ve sarÄ±msaklarÄ± ekleyip kavurmaya devam edin.\n",
            "5.  SalÃ§alarÄ± ekleyin ve kokusu Ã§Ä±kana kadar kavurun. Domatesleri (veya salÃ§ayÄ±) ekleyin.\n",
            "6.  BaharatlarÄ± ve ince kÄ±yÄ±lmÄ±ÅŸ maydanozu ekleyip karÄ±ÅŸtÄ±rÄ±n. HarcÄ± ocaktan alÄ±n.\n",
            "7.  PatlÄ±canlarÄ±n ortasÄ±nÄ± bÄ±Ã§akla Ã§izin ve iÃ§lerini bu harÃ§la doldurun.\n",
            "8.  PatlÄ±canlarÄ± bir fÄ±rÄ±n tepsisine dizin.\n",
            "9.  Sosu iÃ§in salÃ§a ve sÄ±cak suyu karÄ±ÅŸtÄ±rÄ±p tepsiye dÃ¶kÃ¼n.\n",
            "10. Ã–nceden Ä±sÄ±tÄ±lmÄ±ÅŸ 180 derece fÄ±rÄ±nda yaklaÅŸÄ±k 30 dakika piÅŸirin.\n"
          ]
        }
      ]
    }
  ]
}