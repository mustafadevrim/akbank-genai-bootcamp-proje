# -*- coding: utf-8 -*-
import streamlit as st
import google.generativeai as genai
import os
import time

# Gerekli LangChain kÃ¼tÃ¼phaneleri
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.docstore.document import Document
# Chroma ve SelfQueryRetriever importlarÄ±
from langchain_chroma import Chroma
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain.chains.query_constructor.base import AttributeInfo

# --- 1. Konfigurasyon ve API AnahtarÄ± ---

st.set_page_config(
    page_title="TÃ¼rk MutfaÄŸÄ± Tarifi Chatbotu",
    page_icon="ğŸ²"
)
st.title("ğŸ² TÃ¼rk MutfaÄŸÄ± Tarifi Chatbotu")
st.caption("Akbank GenAI Bootcamp Projesi - RAG Chatbot")

try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    if not GOOGLE_API_KEY:
        st.error("GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen Streamlit Secrets'a ekleyin.")
        st.stop()
    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY
    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])
except KeyError:
    st.error("GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen Streamlit Secrets'a ekleyin.")
    st.stop()
except Exception as e:
    st.error(f"API AnahtarÄ± yÃ¼klenirken bir hata oluÅŸtu: {e}")
    st.stop()

# --- 2. Veri YÃ¼kleme ve RAG Mimarisi Kurulumu (SelfQueryRetriever ile) ---

@st.cache_resource
def load_rag_pipeline_self_query():
    """
    Veri setini yÃ¼kler, RAG mimarisini (SelfQueryRetriever ile) kurar.
    AkÄ±llÄ± parÃ§alama mantÄ±ÄŸÄ± iÃ§erir.
    """
    try:
        with st.spinner("ğŸ”„ Veri seti GitHub'dan Ã§ekiliyor..."):
            os.system("rm -rf akbank-genai-bootcamp-proje")
            os.system("git clone https://github.com/mustafadevrim/akbank-genai-bootcamp-proje")

        with st.spinner("ğŸ¥£ Tarifler yÃ¼kleniyor ve AKILLI PARÃ‡ALAMA ile iÅŸleniyor..."):
            with open("akbank-genai-bootcamp-proje/tarifler.txt", "r", encoding="utf-8") as f:
                tum_tarifler_metni = f.read()

            tarif_listesi = tum_tarifler_metni.split("\n---\n")
            documents = []
            basariyla_parcalanan_tarif_sayisi = 0

            for tarif_metni in tarif_listesi:
                if not tarif_metni.strip(): continue

                # Ã–nce BaÅŸlÄ±ÄŸÄ± AyÄ±r
                baslik_parts = tarif_metni.split("\nMalzemeler:\n", 1)
                if len(baslik_parts) < 2:
                    st.warning(f"Format hatasÄ± (Malzemeler bulunamadÄ±): {tarif_metni[:50]}...")
                    continue
                baslik_content = baslik_parts[0].strip()

                # Sonra YapÄ±lÄ±ÅŸÄ± AyÄ±r (Metnin sonundan baÅŸlayarak)
                yapilis_parts = tarif_metni.split("\nYapÄ±lÄ±ÅŸÄ±:\n", 1)
                if len(yapilis_parts) < 2:
                    st.warning(f"Format hatasÄ± (YapÄ±lÄ±ÅŸÄ± bulunamadÄ±): {baslik_content}")
                    continue
                yapilis_content = yapilis_parts[1].strip()

                # BaÅŸlÄ±k ile YapÄ±lÄ±ÅŸÄ± arasÄ±nda kalan her ÅŸeyi Malzemeler (+ ara bÃ¶lÃ¼mler) olarak al
                malzemeler_ve_arasi_content = baslik_parts[1].split("\nYapÄ±lÄ±ÅŸÄ±:\n", 1)[0].strip()

                # Åimdi 3 chunk'Ä± doÄŸru iÃ§erikle oluÅŸturalÄ±m
                doc_metadata = {"source": baslik_content}

                # Chunk 1: Sadece BaÅŸlÄ±k
                documents.append(Document(page_content=baslik_content, metadata=doc_metadata))

                # Chunk 2: BaÅŸlÄ±k + Malzemeler (ve ara bÃ¶lÃ¼mler)
                documents.append(Document(
                    page_content=f"{baslik_content}\nMalzemeler:\n{malzemeler_ve_arasi_content}",
                    metadata=doc_metadata
                ))

                # Chunk 3: BaÅŸlÄ±k + YapÄ±lÄ±ÅŸÄ±
                documents.append(Document(
                    page_content=f"{baslik_content}\nYapÄ±lÄ±ÅŸÄ±:\n{yapilis_content}",
                    metadata=doc_metadata
                ))
                basariyla_parcalanan_tarif_sayisi += 1

            st.info(f"{basariyla_parcalanan_tarif_sayisi} tarif baÅŸarÄ±yla {len(documents)} parÃ§aya bÃ¶lÃ¼ndÃ¼.")
            if not documents:
                st.error("HiÃ§bir tarif parÃ§alanamadÄ± veya tarifler.txt boÅŸ.")
                return None

        with st.spinner("ğŸ§  Embedding modeli (MiniLM) yÃ¼kleniyor..."):
            model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            embeddings = HuggingFaceEmbeddings(model_name=model_name, cache_folder='./embedding_cache')

        with st.spinner("ğŸ“š VektÃ¶r veritabanÄ± (Chroma) oluÅŸturuluyor..."):
            vector_store = Chroma.from_documents(documents, embeddings)

        with st.spinner("ğŸ¤– Generation modeli (Gemini) ve Self-Querying Retriever kuruluyor..."):
            llm_for_retriever = ChatGoogleGenerativeAI(model="models/gemini-flash-latest", temperature=0)

            metadata_field_info = [
                AttributeInfo(
                    name="source",
                    description="Tarifin baÅŸlÄ±ÄŸÄ±, Ã¶rneÄŸin 'BaÅŸlÄ±k: KarnÄ±yarÄ±k' veya 'BaÅŸlÄ±k: Menemen'",
                    type="string",
                ),
            ]
            document_content_description = "TÃ¼rk mutfaÄŸÄ± yemek tarifleri"

            retriever = SelfQueryRetriever.from_llm(
                llm_for_retriever,
                vector_store,
                document_content_description,
                metadata_field_info,
                verbose=False
            )

        llm_for_qa = ChatGoogleGenerativeAI(model="models/gemini-flash-latest", temperature=0.7, top_p=0.85)

        rag_pipeline = RetrievalQA.from_chain_type(
            llm=llm_for_qa,
            chain_type="stuff",
            retriever=retriever
        )

        return rag_pipeline

    except Exception as e:
        st.error(f"RAG Pipeline yÃ¼klenirken hata oluÅŸtu: {e}")
        st.exception(e)
        return None

# RAG Pipeline'Ä± yÃ¼kle
with st.spinner("â³ Chatbot hazÄ±rlanÄ±yor (Self-Querying & AkÄ±llÄ± ParÃ§alama ile)... LÃ¼tfen bekleyin..."):
    rag_chain = load_rag_pipeline_self_query()


# --- 3. Chat ArayÃ¼zÃ¼ ---

if rag_chain is not None:
    st.success("âœ… Chatbot hazÄ±r! Tarif sormaya baÅŸlayabilirsiniz.")

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Merhaba! Hangi TÃ¼rk yemeÄŸi hakkÄ±nda tarif almak istersiniz?"}]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Ã–rn: KÃ¼nefe nasÄ±l yapÄ±lÄ±r?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” Tarif aranÄ±yor (Self-Querying ile) ve cevap oluÅŸturuluyor..."):
                try:
                    response = rag_chain.invoke(prompt)
                    cevap = response['result']
                    st.markdown(cevap)
                    st.session_state.messages.append({"role": "assistant", "content": cevap})
                except Exception as e:
                    st.error(f"Cevap oluÅŸturulurken bir hata oluÅŸtu: {e}")
else:
    st.error("Chatbot yÃ¼klenemedi. LÃ¼tfen API anahtarÄ±nÄ±zÄ± kontrol edin veya sayfayÄ± yenileyin.")
